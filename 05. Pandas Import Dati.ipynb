{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indice",
   "metadata": {},
   "source": [
    "## üìö Indice\n",
    "\n",
    "1. [Introduzione alla Gestione del Sistema Operativo](#1.-Introduzione-alla-Gestione-del-Sistema-Operativo)\n",
    "2. [Gestione e Lettura di Diversi Tipi di File](#2.-Gestione-e-Lettura-di-Diversi-Tipi-di-File)\n",
    "3. [Scrittura di File con Pandas](#3.-Scrittura-di-File-con-Pandas)\n",
    "4. [Unione, Join e Concatenazione di DataFrame](#4.-Unione-Join-e-Concatenazione-di-DataFrame)\n",
    "5. [Aggregazione e Raggruppamento dei Dati](#5.-Aggregazione-e-Raggruppamento-dei-Dati)\n",
    "6. [Automatizzare il Processo di Gestione dei File](#6.-Automatizzare-il-Processo-di-Gestione-dei-File)\n",
    "7. [Esercizi](#7.-Esercizi)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sezione1",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Introduzione alla Gestione del Sistema Operativo\n",
    "\n",
    "Il modulo `os` di Python fornisce numerose funzioni per interagire con il sistema operativo. √à particolarmente utile per navigare nel filesystem, gestire file e directory, e ottenere informazioni sul sistema.\n",
    "\n",
    "**Importante:** Per ulteriori dettagli, puoi consultare la [documentazione ufficiale del modulo `os`](https://docs.python.org/3/library/os.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "navigazione-filesystem",
   "metadata": {},
   "source": [
    "### Navigazione nel Filesystem\n",
    "\n",
    "Possiamo utilizzare `os.listdir()` per elencare i file e le cartelle in una directory, e `os.chdir()` per cambiare la directory corrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listdir-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Elencare i file nella current working directory\n",
    "files = os.listdir()\n",
    "print(\"Contenuto della directory:\")\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7417d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f5f5f5; padding:12px 14px; border-left:4px solid #5cb85c; border-radius:2px;\">\n",
    "\n",
    "**Esercizio**\n",
    "\n",
    "Fai print della lista dei file nella cartella Dati\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggerimento: specifica \"Dati\" in listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gestione-file-directory",
   "metadata": {},
   "source": [
    "### Gestione di File e Directory\n",
    "\n",
    "Possiamo creare, rinominare e rimuovere file e directory utilizzando funzioni come `os.mkdir()`, `os.rename()`, `os.remove()`, ecc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkdir-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare una nuova directory\n",
    "if not os.path.exists('Nuova Cartella'):\n",
    "    os.mkdir('Nuova Cartella')\n",
    "    print(\"Directory 'Nuova Cartella' creata.\")\n",
    "else:\n",
    "    print(\"La directory 'Nuova Cartella' esiste gi√†.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rename-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rinominare la directory\n",
    "if os.path.exists('Nuova Cartella'):\n",
    "    os.rename('Nuova Cartella', 'Cartella Rinominata')\n",
    "    print(\"Directory rinominata in 'Cartella Rinominata'.\")\n",
    "else:\n",
    "    print(\"La directory 'Nuova Cartella' non esiste.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remove-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimuovere la directory\n",
    "if os.path.exists('Cartella Rinominata'):\n",
    "    os.rmdir('Cartella Rinominata')\n",
    "    print(\"Directory 'Cartella Rinominata' rimossa.\")\n",
    "else:\n",
    "    print(\"La directory 'Cartella Rinominata' non esiste.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sezione2",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Gestione e Lettura di Diversi Tipi di File\n",
    "\n",
    "In questa sezione esploreremo come utilizzare Pandas per leggere diversi tipi di file: CSV, Excel, Parquet e come interagire con API per recuperare dati da servizi web.\n",
    "\n",
    "**Nota:** Assicuriamoci di avere importato Pandas e altre librerie necessarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importare le librerie necessarie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-csv",
   "metadata": {},
   "source": [
    "### 2.1  File CSV\n",
    "\n",
    "I file CSV (*Comma-Separated Values*) sono uno dei formati pi√π comuni per l'archiviazione e lo scambio di dati tabulari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb015fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggere un file CSV\n",
    "df_turbine = pd.read_csv('Dati/TexasTurbine.csv')\n",
    "df_turbine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trovare-leggere-csv",
   "metadata": {},
   "source": [
    "#### Trovare e Leggere File CSV in una Directory\n",
    "\n",
    "Possiamo utilizzare `os.listdir()` o il modulo `glob` per individuare file con estensione `.csv`.\n",
    "\n",
    "**Esempio:** Creiamo alcuni file CSV di esempio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-csv-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "# Creiamo alcuni DataFrame di esempio\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Nome': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Et√†': ['25', '30', '35']  # Intenzionalmente come stringhe\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [4, 5, 6],\n",
    "    'Nome': ['David', 'Eva', 'Frank'],\n",
    "    'Et√†': ['40', '45', '50']  # Intenzionalmente come stringhe\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo i DataFrame come file CSV\n",
    "df1.to_csv('dati1.csv', index=False)\n",
    "df2.to_csv('dati2.csv', index=False)\n",
    "print(\"File 'dati1.csv' e 'dati2.csv' creati.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "glob-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizzare glob per trovare file CSV\n",
    "csv_files = glob('*.csv')\n",
    "print(\"File CSV trovati:\")\n",
    "for file in csv_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lettura-csv",
   "metadata": {},
   "source": [
    "#### Lettura di file CSV utilizzando `pandas.read_csv()`\n",
    "\n",
    "Pandas fornisce la funzione `read_csv()` per leggere file CSV in un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere il primo file CSV\n",
    "df_csv1 = pd.read_csv('dati1.csv')\n",
    "df_csv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specificare-dtypes",
   "metadata": {},
   "source": [
    "#### Specificare i Tipi di Dato durante la Lettura di CSV\n",
    "\n",
    "Durante la lettura di un file CSV, Pandas tenta di inferire automaticamente i tipi di dati delle colonne. Tuttavia, a volte √® necessario specificare manualmente il tipo di dato di una o pi√π colonne utilizzando il parametro `dtype`.\n",
    "\n",
    "**Esempio:** Supponiamo che la colonna 'Et√†' sia stata letta come stringa, ma vogliamo assicurarci che sia interpretata come intero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-csv-dtype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere il CSV specificando i tipi di dato\n",
    "dtype_spec = {'ID': int, 'Nome': str, 'Et√†': int}\n",
    "df_csv1_typed = pd.read_csv('dati1.csv', dtype=dtype_spec)\n",
    "df_csv1_typed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dtype-explanation",
   "metadata": {},
   "source": [
    "In questo modo, garantiamo che la colonna 'Et√†' sia letta come intero. Questo √® particolarmente utile quando si lavora con grandi dataset e si desidera ottimizzare l'uso della memoria o evitare errori di tipo.\n",
    "\n",
    "#### Altri Parametri Utili in `read_csv()`\n",
    "\n",
    "- **`usecols`**: Specifica quali colonne leggere dal file.\n",
    "- **`sep`**: Specifica il delimitatore (, ; \\t).\n",
    "- **`decimal`**: Specifica il separatore dei decimali (es. ',' invece di '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrazione-csv",
   "metadata": {},
   "source": [
    "#### Integrazione di Dati da Pi√π File CSV\n",
    "\n",
    "Possiamo concatenare pi√π DataFrame provenienti da diversi file CSV utilizzando `pd.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-csv-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere tutti i file CSV e aggiungerli a una lista\n",
    "dfs = []\n",
    "for filename in csv_files:\n",
    "    df = pd.read_csv(filename, dtype=dtype_spec)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a11688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenare i DataFrame\n",
    "df_concatenated = pd.concat(dfs, ignore_index=True)\n",
    "df_concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-excel",
   "metadata": {},
   "source": [
    "### 2.2 File Excel\n",
    "\n",
    "I file Excel sono ampiamente utilizzati per i dati strutturati e possono contenere pi√π fogli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12773785",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_italian_load = pd.read_excel('Dati/load_total_north_hourly_2024.xlsx')\n",
    "df_italian_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lettura-excel",
   "metadata": {},
   "source": [
    "#### Lettura di File Excel con Pi√π Fogli\n",
    "\n",
    "Possiamo utilizzare `pandas.read_excel()` per leggere file Excel e specificare il foglio da leggere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-excel-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare un file Excel con pi√π fogli\n",
    "with pd.ExcelWriter('dati.xlsx') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Foglio1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Foglio2', index=False)\n",
    "print(\"File 'dati.xlsx' creato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-excel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere un foglio specifico\n",
    "df_foglio1 = pd.read_excel('dati.xlsx', sheet_name='Foglio1', dtype=dtype_spec)\n",
    "df_foglio1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrazione-excel",
   "metadata": {},
   "source": [
    "#### Integrazione di Dati da Diversi Fogli Excel\n",
    "\n",
    "Possiamo leggere pi√π fogli e unirli in un unico DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-excel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere tutti i fogli dal file Excel\n",
    "excel_file = pd.ExcelFile('dati.xlsx')\n",
    "dfs_excel = []\n",
    "for sheet_name in excel_file.sheet_names:\n",
    "    df = pd.read_excel('dati.xlsx', sheet_name=sheet_name, dtype=dtype_spec)\n",
    "    dfs_excel.append(df)\n",
    "\n",
    "# Concatenare i DataFrame\n",
    "df_excel_concatenated = pd.concat(dfs_excel, ignore_index=True)\n",
    "df_excel_concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-parquet",
   "metadata": {},
   "source": [
    "### 2.3 üóÑÔ∏è File Parquet\n",
    "\n",
    "Il formato Parquet √® un formato di archiviazione colonnare ottimizzato per l'uso con big data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introduzione-parquet",
   "metadata": {},
   "source": [
    "#### Introduzione ai File Parquet\n",
    "\n",
    "I file Parquet offrono:\n",
    "\n",
    "- **Efficienza di storage**: grazie alla compressione dei dati.\n",
    "- **Velocit√† di lettura/scrittura**: specialmente per dataset di grandi dimensioni.\n",
    "\n",
    "**Nota:** Per utilizzare Parquet con Pandas, potrebbe essere necessario installare librerie aggiuntive come `pyarrow` o `fastparquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-pyarrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installare pyarrow se non √® gi√† installato\n",
    "!pip install pyarrow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lettura-parquet",
   "metadata": {},
   "source": [
    "#### Lettura e Scrittura di File Parquet con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write-parquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrivere un DataFrame in formato Parquet\n",
    "df_concatenated.to_parquet('dati.parquet', index=False)\n",
    "print(\"File 'dati.parquet' creato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read-parquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggere il file Parquet\n",
    "df_parquet = pd.read_parquet('dati.parquet')\n",
    "df_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sezione-api",
   "metadata": {},
   "source": [
    "### 2.4 üåê Lettura di Dati da API\n",
    "\n",
    "Le API (*Application Programming Interface*) permettono di accedere a dati e servizi offerti da applicazioni web. In questa sezione, vedremo come utilizzare le API per recuperare dati e trasformarli in un DataFrame Pandas.\n",
    "\n",
    "#### Introduzione alle API e al loro Utilizzo\n",
    "\n",
    "Un'API √® un insieme di regole che permette a programmi diversi di comunicare tra loro. Molte organizzazioni e servizi web forniscono API pubbliche per accedere ai loro dati.\n",
    "\n",
    "Per interagire con un'API, solitamente si invia una richiesta HTTP (ad esempio, una richiesta GET) a un endpoint specifico, e si riceve una risposta, spesso in formato JSON.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba2b81-b724-400c-8f45-6acdb51404f3",
   "metadata": {},
   "source": [
    "#### Cos'√® JSON?\n",
    "\n",
    "JSON (*JavaScript Object Notation*) √® un formato di testo per lo scambio di dati, strutturato in coppie chiave-valore simili ai dizionari Python. √à comunemente usato per inviare dati tra server e applicazioni web grazie alla sua leggibilit√† e compatibilit√† tra diversi linguaggi.\n",
    "\n",
    "**Esempio di JSON**:\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Alice\",\n",
    "  \"age\": 30,\n",
    "  \"city\": \"Rome\",\n",
    "  \"interests\": [\"reading\", \"hiking\", \"coding\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02987ca-9594-4301-bad6-fbf0637c9bb3",
   "metadata": {},
   "source": [
    "#### Lettura di Dati da API con Python\n",
    "\n",
    "In Python, la libreria `requests` facilita l'invio di richieste HTTP. Possiamo utilizzarla per recuperare dati da un'API e poi utilizzare Pandas per analizzarli.\n",
    "\n",
    "**Passi Generali:**\n",
    "\n",
    "1. Importare le librerie necessarie (`requests`, `pandas`).\n",
    "2. Definire l'endpoint API e i parametri della richiesta.\n",
    "3. Inviare la richiesta e ottenere la risposta.\n",
    "4. Convertire i dati JSON ricevuti in un DataFrame Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "esempio-api",
   "metadata": {},
   "source": [
    "#### Esempio Pratico: Recupero di Dati Meteo dalla Regione Lombardia\n",
    "\n",
    "Utilizzeremo l'API dei dati aperti della Regione Lombardia per recuperare informazioni sulle stazioni idro-nivo-meteorologiche.\n",
    "\n",
    "**Risorse:**\n",
    "\n",
    "- **Anagrafica Sensori:**\n",
    "  - Endpoint: https://www.dati.lombardia.it/resource/nf78-nj6b.json\n",
    "  - Descrizione: Contiene le informazioni di anagrafica delle stazioni di misura.\n",
    "- **Misure dei Sensori:**\n",
    "  - Endpoint: https://www.dati.lombardia.it/resource/647i-nhxk.json\n",
    "  - Descrizione: Contiene le misure rilevate dai sensori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importare le librerie necessarie\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26491227-2899-4833-b698-211156de226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scegliamo un endpoint \n",
    "url = \"https://www.dati.lombardia.it/resource/nf78-nj6b.json\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a19047-ee7b-4b47-bd1e-0c470478fb7a",
   "metadata": {},
   "source": [
    "#### Codici di Stato HTTP\n",
    "\n",
    "Quando inviamo una richiesta a un'API, riceviamo un *codice di stato* che indica l'esito della richiesta. \n",
    "\n",
    "- **200**: Successo! La richiesta √® stata completata correttamente.\n",
    "- **404**: Risorsa non trovata. L'URL potrebbe essere errato.\n",
    "- **500**: Errore del server. Il problema √® lato server.\n",
    "\n",
    "Controllare il codice di stato ci aiuta a gestire gli errori e capire se la richiesta ha avuto successo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20357773-2fdb-4c31-b8ef-92275deaeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = response.json()\n",
    "len(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f90787-ffeb-43f2-a81e-49270ef97618",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5b422-4ae5-44a3-9821-b0c6d589685f",
   "metadata": {},
   "source": [
    "#### Filtrare i Dati con i Parametri di Query\n",
    "\n",
    "Quando interagiamo con un'API, potremmo non voler recuperare tutti i dati disponibili, ma solo una parte specifica. Qui entrano in gioco i **parametri di query**: opzioni aggiuntive che possiamo includere nell'URL per filtrare o selezionare un sottoinsieme di dati.\n",
    "\n",
    "A\n",
    "Per richiedere dati specifici da un'API, possiamo utilizzare i **parametri di query**, che vengono aggiunti alla fine dell'URL per filtrare o personalizzare la richiesta. Ecco la sintassi di base:\n",
    "\n",
    "- Ogni parametro di query √® aggiunto dopo il simbolo `?`, che segna l'inizio della sezione dei parametri.\n",
    "- I parametri sono scritti come coppie `chiave=valore`.\n",
    "- Se ci sono pi√π parametri, vengono separati da `&`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3cb21-6c0d-4f72-89bf-8c89c0a399aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL con parametro di query per la provincia di Milano\n",
    "url = \"https://www.dati.lombardia.it/resource/nf78-nj6b?provincia=MI&tipologia=Precipitazione\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Visualizza i dati filtrati\n",
    "display(data[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebd926-aabf-4aa3-bae3-199401a8135a",
   "metadata": {},
   "source": [
    "In Python, possiamo semplificare questa sintassi usando l'argomento params con la libreria requests. params accetta un dizionario con i parametri e i loro valori, rendendo il codice pi√π leggibile e facile da gestire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d83d57-949c-4abe-8516-17420cbde6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo i parametri di query come un dizionario\n",
    "params = {\n",
    "    \"provincia\": \"MI\",\n",
    "    \"tipologia\": \"Precipitazione\"\n",
    "}\n",
    "\n",
    "# Effettuiamo la richiesta GET usando 'params' per i parametri di query\n",
    "url = \"https://www.dati.lombardia.it/resource/nf78-nj6b\"\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Visualizziamo i dati filtrati\n",
    "display(data[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funzione-get-data",
   "metadata": {},
   "source": [
    "#### Definire una Funzione per Recuperare Dati da un'API\n",
    "\n",
    "Per rendere il codice pi√π riutilizzabile, definiamo una funzione che prende un URL e dei parametri, invia una richiesta all'API e restituisce un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-get-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url, params=None):\n",
    "    \"\"\"\n",
    "    Recupera dati da un'API e li converte in un DataFrame Pandas.\n",
    "    \n",
    "    Args:\n",
    "        url (str): L'endpoint API.\n",
    "        params (dict): I parametri della richiesta.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Il DataFrame con i dati ottenuti.\n",
    "    \"\"\"\n",
    "    # Invia la richiesta GET all'API\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    # Controlla se la richiesta ha avuto successo\n",
    "    if response.status_code == 200:\n",
    "        # Converte i dati JSON in un DataFrame\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame.from_records(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Errore nella richiesta: {response.status_code}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recupero-sensori",
   "metadata": {},
   "source": [
    "#### Recuperare l'Anagrafica dei Sensori\n",
    "\n",
    "Iniziamo recuperando le informazioni sui sensori disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definire l'endpoint e i parametri\n",
    "sensors_url = \"https://www.dati.lombardia.it/resource/nf78-nj6b.json\"\n",
    "params = {\n",
    "    \"$limit\": 5000  # Impostiamo un limite alto per ottenere tutti i record\n",
    "}\n",
    "# parametri di query speciali iniziano con il simbolo `$`. \n",
    "# Questi parametri servono per configurare richieste avanzate, come limitare il numero di record, ordinare o applicare filtri specifici.\n",
    "\n",
    "\n",
    "# Recuperare i dati\n",
    "sensori_df = get_data(sensors_url, params)\n",
    "sensori_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "esplorazione-sensori",
   "metadata": {},
   "source": [
    "Possiamo ora esplorare il DataFrame `sensori_df` per capire quali tipi di sensori sono disponibili e in quali province."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipologie di sensori disponibili\n",
    "sensori_df['tipologia'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Province disponibili\n",
    "sensori_df['provincia'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizza la posizione geografica dei sensori in una mappa con location\n",
    "# es {'type': 'Point', 'coordinates': [9.56265997, 45.26927396]}\n",
    "import plotly.express as px\n",
    "fig = px.scatter_mapbox(\n",
    "    sensori_df,\n",
    "    lat=sensori_df['location'].apply(lambda loc: loc['coordinates'][1]),\n",
    "    lon=sensori_df['location'].apply(lambda loc: loc['coordinates'][0]),\n",
    "    hover_name=\"tipologia\",\n",
    "    zoom=8,\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filtrare-sensori",
   "metadata": {},
   "source": [
    "Supponiamo di voler ottenere tutti i sensori di temperatura nella provincia di Milano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter-sensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrare i sensori di temperatura nella provincia di Milano\n",
    "sensori_milano = sensori_df[(sensori_df['tipologia'] == 'Temperatura') & (sensori_df['provincia'] == 'MI')]\n",
    "sensori_milano.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recupero-misure",
   "metadata": {},
   "source": [
    "#### Recuperare le Misure dei Sensori\n",
    "\n",
    "Ora che abbiamo gli ID dei sensori di interesse, possiamo recuperare le misure associate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-measurements",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scegliere un IDsensore (ad esempio, il primo)\n",
    "idsensore = sensori_milano['idsensore'].iloc[1]\n",
    "print(f\"Recupero dei dati per IDsensore: {idsensore}\")\n",
    "\n",
    "# Definire l'endpoint delle misure\n",
    "measurements_url = f\"https://www.dati.lombardia.it/resource/647i-nhxk.json\"\n",
    "\n",
    "# Aggiornare i parametri per filtrare per IDsensore\n",
    "params_misure = {\n",
    "        \"idsensore\": idsensore,\n",
    "        \"$limit\": 100000\n",
    "}\n",
    "\n",
    "# Recuperare le misure\n",
    "misure_df = get_data(measurements_url, params_misure)\n",
    "misure_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analisi-misure",
   "metadata": {},
   "source": [
    "#### Analizzare e Visualizzare le Misure\n",
    "\n",
    "Possiamo ora analizzare le misure ottenute e, ad esempio, visualizzare l'andamento della temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertire la colonna 'dataora' in datetime\n",
    "misure_df['data'] = pd.to_datetime(misure_df['data'])\n",
    "\n",
    "# Assicurarci che 'valore' sia numerico\n",
    "misure_df['valore'] = pd.to_numeric(misure_df['valore'], errors='coerce')\n",
    "\n",
    "# Ordinare i dati per data\n",
    "misure_df = misure_df.sort_values('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df_plot = misure_df.iloc[-100:]\n",
    "\n",
    "fig = px.line(\n",
    "    df_plot,\n",
    "    x=\"data\",\n",
    "    y=\"valore\",\n",
    "    markers=True,\n",
    "    title=f\"Andamento della Temperatura per IDsensore {idsensore}\",\n",
    "    labels={\n",
    "        \"data\": \"Data e Ora\",\n",
    "        \"valore\": \"Temperatura (¬∞C)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sezione4",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Unione, Join e Concatenazione di DataFrame\n",
    "\n",
    "Pandas offre potenti strumenti per combinare DataFrame in vari modi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "merge",
   "metadata": {},
   "source": [
    "### Merge\n",
    "\n",
    "Il metodo `merge()` consente di combinare DataFrame basati su chiavi comuni, simile a un join in SQL.\n",
    "\n",
    "**Tipi di join:**\n",
    "- **Inner Join**: Restituisce le righe con chiavi corrispondenti in entrambi i DataFrame.\n",
    "- **Left Join**: Restituisce tutte le righe del DataFrame di sinistra e le righe corrispondenti del DataFrame di destra.\n",
    "- **Right Join**: Restituisce tutte le righe del DataFrame di destra e le righe corrispondenti del DataFrame di sinistra.\n",
    "- **Outer Join**: Restituisce tutte le righe quando c'√® una corrispondenza in uno dei DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare DataFrame di esempio\n",
    "df_left = pd.DataFrame({'ID': [1, 2, 3], 'Nome': ['Alice', 'Bob', 'Charlie']})\n",
    "df_right = pd.DataFrame({'ID': [3, 4, 5], 'Et√†': [35, 40, 45]})\n",
    "\n",
    "# Esempio di Inner Join\n",
    "df_inner = pd.merge(df_left, df_right, on='ID', how='inner')\n",
    "df_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di Outer Join\n",
    "df_outer = pd.merge(df_left, df_right, on='ID', how='outer')\n",
    "df_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concat",
   "metadata": {},
   "source": [
    "### Concatenazione\n",
    "\n",
    "Il metodo `concat()` consente di unire DataFrame verticalmente (aggiungere righe) o orizzontalmente (aggiungere colonne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenazione verticale\n",
    "df_concat_vertical = pd.concat([df_left, df_right], ignore_index=True, sort=False)\n",
    "df_concat_vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenazione orizzontale\n",
    "df_concat_horizontal = pd.concat([df_left, df_right], axis=1)\n",
    "df_concat_horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differenze-merge-concat",
   "metadata": {},
   "source": [
    "### Differenze e Casi d'Uso di Merge e Concat\n",
    "\n",
    "- **Merge**: quando si desidera combinare DataFrame su una o pi√π chiavi comuni.\n",
    "- **Concat**: quando si desidera unire DataFrame che hanno le stesse colonne o indici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregation-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolare la media dei valori per categoria\n",
    "df_grouped_mean = df_group.groupby('Categoria').mean()\n",
    "df_grouped_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f9f26-a67a-49e5-8b04-4ca371cb110c",
   "metadata": {},
   "source": [
    "# Esercizi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3feb98f-57f3-40da-9823-d01e23969af0",
   "metadata": {},
   "source": [
    "## Esercizio 1\n",
    "In questo esercizio, useremo Python per accedere ai dati sulla certificazione energetica degli edifici in Lombardia e fare alcune analisi per la provincia di Milano.\n",
    "\n",
    "### Obiettivi\n",
    "1. **Recuperare i dati** relativi alla certificazione energetica degli edifici in Lombardia utilizzando una richiesta HTTP.\n",
    "2. **Selezionare solo i dati della provincia di Milano**.\n",
    "3. **Calcolare le emissioni di CO2** per ciascuna classe energetica.\n",
    "\n",
    "### Hint\n",
    "L'endpoint per accedere ai dati in formato JSON √®:\n",
    "- `https://www.dati.lombardia.it/resource/rsg3-xhvk.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17ff1d-9db0-4a1d-974b-7a3b90f1f2c9",
   "metadata": {},
   "source": [
    "## Esercizio 2: Analisi dei Dati di Produzione Elettrica\n",
    "\n",
    "In questo esercizio, useremo Python per accedere a una sorgente di dati sul sistema elettrico in tempo reale, utilizzando la libreria `requests` per ottenere i dati e `pandas` per fare alcune analisi di base.\n",
    "\n",
    "### Obiettivi\n",
    "1. **Recuperare i dati in formato JSON** dalla sorgente dati tramite una richiesta HTTP.\n",
    "2. **Organizzare i dati in un DataFrame** di `pandas` per facilitare l'analisi.\n",
    "3. **Calcolare la produzione media di energia** per ciascun tipo di fonte energetica.\n",
    "\n",
    "### Passaggi\n",
    "\n",
    "1. **Importare le librerie** necessarie: `requests` e `pandas`.\n",
    "2. **Recuperare i dati** tramite un'API HTTP utilizzando `requests.get()`.\n",
    "3. **Creare un DataFrame** con i dati ottenuti e fare un controllo delle prime righe.\n",
    "4. **Usare `groupby`** su una colonna rilevante (ad esempio, il tipo di produzione energetica) per calcolare la produzione media.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b58ed-39c3-4af4-aba1-701bc3c5e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Passo 1: Recupera i dati\n",
    "url = \"https://www.energidataservice.dk/api/PowerSystemRightNow\"  \n",
    "response = ...  # use get\n",
    "data = ... # use .json\n",
    "\n",
    "# Passo 2: Crea un DataFrame\n",
    "df = pd.DataFrame(data['records'])  \n",
    "print(df.head())\n",
    "\n",
    "# Passo 3: Calcola la produzione media per tipo di energia\n",
    "average_production = df.groupby...\n",
    "print(\"Produzione media per tipo di energia:\")\n",
    "print(average_production)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
