{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3107a71f",
   "metadata": {},
   "source": [
    "# Progetto — Previsione del carico elettrico\n",
    "\n",
    "In questo progetto affrontiamo un caso reale di **previsione del carico elettrico**.\n",
    "\n",
    "I dati utilizzati provengono dal **Download Center di Terna**  \n",
    "https://dati.terna.it/en/download-center  \n",
    "\n",
    "In particolare, useremo i dati di **carico elettrico della zona Nord** relativi agli anni **2024 e 2025**.  \n",
    "Nei dataset Terna, il carico elettrico rappresenta la **potenza richiesta al sistema elettrico in ciascun intervallo temporale** ed è una grandezza centrale per la pianificazione e la gestione operativa della rete di trasmissione.\n",
    "\n",
    "L’obiettivo dell’esercizio è utilizzare queste osservazioni storiche per **prevedere l’andamento del carico nei primi giorni del 2026**, riproducendo in forma semplificata un problema tipico affrontato dagli operatori di sistema.\n",
    "\n",
    "Accanto alla serie storica del carico, integreremo **dati di temperatura** ottenuti tramite API da Open-Meteo  \n",
    "https://open-meteo.com  \n",
    "\n",
    "La temperatura verrà utilizzata come **variabile esogena** a supporto della previsione, per mostrare come informazioni esterne possano migliorare un modello di forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3e6320",
   "metadata": {},
   "source": [
    "# STEP 1: Caricamento dei dati e unione\n",
    "\n",
    "In questo step costruiamo una singola serie storica continua a partire dai dati grezzi.\n",
    "\n",
    "1. Leggi i due file Excel presenti nella cartella `Dati/`:\n",
    "   - `load_total_north_hourly_2024.xlsx`\n",
    "   - `load_total_north_hourly_2025.xlsx`\n",
    "\n",
    "2. Unisci i due dataset **per righe**, mantenendo lo stesso schema di colonne, in modo da ottenere una serie unica che copra l’intero periodo 2024–2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fai l'import di pandas\n",
    "\n",
    "# Carica i dati dei due anni (df_2024 e df_2025)\n",
    "\n",
    "# Unisci i due dataset per righe (pd.concat con ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148ee62",
   "metadata": {},
   "source": [
    "# STEP 2: Preparazione della colonna temporale e prima visualizzazione\n",
    "\n",
    "In questo step rendiamo la colonna data utilizzabile come variabile temporale e facciamo una prima ispezione visiva della serie.\n",
    "\n",
    "1. Identifica la colonna che contiene la data/ora e trasformala in formato `datetime`.\n",
    "   - Se la data è letta come stringa, la convertiamo con `pd.to_datetime(...)`.\n",
    "\n",
    "2. Ordina il dataset per data (anche se sembra già ordinato) e reimposta l’indice per avere un ordinamento pulito.\n",
    "\n",
    "3. Importa Plotly e visualizza **entrambe** le serie nel tempo:\n",
    "   - `Total Load [MW]`\n",
    "   - `Forecast Total Load [MW]`\n",
    "\n",
    "4. Dopo aver verificato che le due curve siano coerenti, elimina le colonne che non useremo nel forecasting:\n",
    "   - `Forecast Total Load [MW]`\n",
    "   - `Bidding Zone`\n",
    "\n",
    "Al termine di questo step deve rimanere una serie storica con:\n",
    "- una colonna temporale in formato `datetime`;\n",
    "- una sola colonna target (`Total Load [MW]`), pronta per essere rinominata in `y` più avanti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77447078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Converti la colonna Date in formato datetime\n",
    "\n",
    "# Ordina per data \n",
    "\n",
    "# resetta l'indice (df = df.reset_index(drop=True))\n",
    "\n",
    "# Elimina le colonne non necessarie ( Forecast Total Load [MW] e Bidding Zone )\n",
    "\n",
    "# Visualizza Total Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536932c",
   "metadata": {},
   "source": [
    "# STEP 3: Aggregazioni temporali e profili medi\n",
    "\n",
    "In questo step analizziamo la serie oraria cambiando punto di vista sul tempo.  \n",
    "Costruiamo una serie giornaliera e osserviamo pattern medi legati all’ora del giorno e al giorno della settimana.\n",
    "\n",
    "Useremo:\n",
    "- `Date` come colonna temporale;\n",
    "- `Total Load [MW]` come variabile di interesse.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Serie giornaliera (somma)\n",
    "\n",
    "Esegui i passaggi seguenti nell’ordine:\n",
    "\n",
    "1. Parti dal DataFrame orario `df`.\n",
    "\n",
    "2. Imposta la colonna `Date` come indice temporale.\n",
    "\n",
    "3. Aggrega per giorno usando `resample(\"D\")` e calcola la **somma** del carico.\n",
    "\n",
    "4. Riporta `Date` come colonna e salva il risultato in `df_daily`.\n",
    "\n",
    "5. Visualizza la serie giornaliera con Plotly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e082bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3.1 Serie giornaliera (somma)\n",
    "# =============================================================================\n",
    "\n",
    "# 1-2. Imposta Date come indice\n",
    "\n",
    "# 3. Aggrega per giorno (somma) hint: resample come visto nel notebook 06\n",
    "df_daily = ...\n",
    "\n",
    "# 4. Riporta Date come colonna (reset index) - completo: basta rimuovere il commento\n",
    "# df_daily = df_daily.reset_index()\n",
    "\n",
    "# 5. Visualizza la serie giornaliera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9613a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.2 Profilo medio giornaliero (media per ora del giorno)\n",
    "\n",
    "Ora torniamo alla serie oraria originale.\n",
    "\n",
    "6. Estrai l’**ora del giorno** dalla colonna `Date` e salvala in una nuova colonna `hour`.\n",
    "\n",
    "7. Raggruppa per `hour` e calcola la **media** del carico.\n",
    "\n",
    "8. Visualizza il profilo medio giornaliero con Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb352c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3.2 Profilo medio giornaliero (media per ora del giorno)\n",
    "# =============================================================================\n",
    "\n",
    "# 6. Estrai l'ora del giorno (usa dt e hour) come in notebook 06\n",
    "\n",
    "# 7. Raggruppa per hour e calcola la media (hint: groupby, mean, reset_index)\n",
    "hourly_profile = ...\n",
    "\n",
    "# 8. Visualizza il profilo medio giornaliero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f00d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.3 Profilo medio settimanale (media per giorno della settimana)\n",
    "\n",
    "Sempre partendo dalla serie oraria originale:\n",
    "\n",
    "9. Estrai il **giorno della settimana** dalla colonna `Date` e salvalo in una nuova colonna `weekday`\n",
    "   - usa la convenzione: `0 = Lunedì, …, 6 = Domenica`.\n",
    "\n",
    "10. Raggruppa per `weekday` e calcola la **media** del carico.\n",
    "\n",
    "11. Visualizza il profilo medio settimanale con Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f485a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3.3 Profilo medio settimanale (media per giorno della settimana)\n",
    "# =============================================================================\n",
    "\n",
    "# 9. Estrai il giorno della settimana (0=Lunedì, 6=Domenica) - hint: dt e dayofweek\n",
    "df['weekday'] = ...\n",
    "\n",
    "# 10. Raggruppa per weekday e calcola la media (hint: groupby, mean, reset_index)\n",
    "\n",
    "# Aggiungi etichette leggibili per i giorni (completo: basta rimuovere il commento)\n",
    "#weekday_names = ['Lunedì', 'Martedì', 'Mercoledì', 'Giovedì', 'Venerdì', 'Sabato', 'Domenica']\n",
    "#weekly_profile['day_name'] = weekly_profile['weekday'].map(lambda x: weekday_names[x])\n",
    "\n",
    "# 11. Visualizza il profilo medio settimanale (line plot)\n",
    "\n",
    "# .. completa qui ...\n",
    "#fig.update_xaxes(categoryorder='array', categoryarray=weekday_names)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b751562",
   "metadata": {},
   "source": [
    "# STEP 4: Primo modello di forecasting con Prophet (univariato)\n",
    "\n",
    "In questo step costruiamo il **primo modello di forecasting** utilizzando esclusivamente la serie storica del carico elettrico.\n",
    "\n",
    "L’obiettivo è:\n",
    "- preparare i dati nel formato richiesto da Prophet;\n",
    "- addestrare un modello base;\n",
    "- generare una previsione su un orizzonte temporale realistico;\n",
    "- osservare sia la previsione sia le componenti stimate dal modello.\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Preparazione del dataset per Prophet\n",
    "\n",
    "Prophet richiede un DataFrame con **due sole colonne**:\n",
    "- `ds`: variabile temporale (`datetime`);\n",
    "- `y`: variabile da prevedere.\n",
    "\n",
    "Esegui i passaggi seguenti:\n",
    "\n",
    "1. Seleziona dal DataFrame originale solo le colonne:\n",
    "   - `Date`\n",
    "   - `Total Load [MW]`\n",
    "\n",
    "2. Rinominale rispettivamente in:\n",
    "   - `ds`\n",
    "   - `y`\n",
    "\n",
    "3. Verifica che:\n",
    "   - `ds` sia in formato `datetime`;\n",
    "   - non ci siano valori mancanti;\n",
    "   - le osservazioni siano ordinate nel tempo.\n",
    "\n",
    "---\n",
    "## 4.2 Inizializzazione e addestramento del modello\n",
    "\n",
    "Ora inizializziamo un modello Prophet **standard**, senza configurazioni avanzate.\n",
    "\n",
    "1. Crea un’istanza del modello.\n",
    "2. Addestra il modello sui dati storici usando `fit`.\n",
    "\n",
    "In questa fase Prophet:\n",
    "- analizza il trend;\n",
    "- stima le stagionalità;\n",
    "- apprende la struttura della serie dal passato.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Preparazione del dataset per Prophet (univariato)\n",
    "# -------------------------------------------------\n",
    "df_prophet = ...\n",
    "\n",
    "df_prophet = df_prophet.reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Inizializzazione e fit del modello\n",
    "# -------------------------------------------------\n",
    "\n",
    "# ... completa qui ...\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Costruzione del periodo futuro e previsione\n",
    "# Orizzonte: 7 giorni (orario)\n",
    "# -------------------------------------------------\n",
    "# hint: make_future_dataframe (7 giorni: quanti 15 min?)\n",
    "\n",
    "# hint: predict \n",
    "\n",
    "# -------------------------------------------------\n",
    "# Visualizzazione previsione e componenti\n",
    "# -------------------------------------------------\n",
    "# hint: plot_plotly , plot_components_plotly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16eb8d3",
   "metadata": {},
   "source": [
    "# STEP 5: Recupero e integrazione della temperatura (Open-Meteo)\n",
    "\n",
    "In questo step aggiungiamo una variabile esogena: la **temperatura a 2 metri** misurata/ricostruita per Milano.\n",
    "È una semplificazione: usiamo Milano come proxy “medio” per il Nord Italia.\n",
    "\n",
    "Useremo l’API **Historical Weather** di Open-Meteo:\n",
    "- non serve alcuna chiave API;\n",
    "- possiamo chiedere i dati **orari** su un intervallo di date.\n",
    "\n",
    "Documentazione:\n",
    "- Historical Weather API: https://open-meteo.com/en/docs/historical-weather-api\n",
    "- Home / overview: https://open-meteo.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cella completa: leggete bene il codice\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# intervallo dal dataset\n",
    "start_date = df['Date'].min().strftime('%Y-%m-%d')\n",
    "end_date = df['Date'].max().strftime('%Y-%m-%d') \n",
    "print('Intervallo:', start_date, '->', end_date)\n",
    "\n",
    "# Milano (punto rappresentativo Nord Italia per esercizio)\n",
    "lat, lon = 45.4642, 9.1900\n",
    "\n",
    "# Open-Meteo – storico orario\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    \"latitude\": lat,\n",
    "    \"longitude\": lon,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date,\n",
    "    \"hourly\": \"temperature_2m\",\n",
    "    \"timezone\": \"Europe/Rome\" # \"UTC\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=params, timeout=20)\n",
    "r.raise_for_status()\n",
    "\n",
    "# DataFrame temperatura\n",
    "hourly = r.json()[\"hourly\"]\n",
    "w = pd.DataFrame(hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50792194",
   "metadata": {},
   "outputs": [],
   "source": [
    "w[\"time\"] = pd.to_datetime(w[\"time\"])\n",
    "w = w.rename(columns={\n",
    "    \"time\": \"Date\",\n",
    "    \"temperature_2m\": \"Temperature_C\"\n",
    "})\n",
    "w[\"Date\"] = pd.to_datetime(w[\"Date\"])\n",
    "w = w.set_index(\"Date\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0abec",
   "metadata": {},
   "source": [
    "Ora dobbiamo integrare il dato di temperatura con il dato di load. Per prima cosa va risolto la differente granularità, visto che il dato medio lo abbiamo solo orario (upsampling h -> 15min)\n",
    "\n",
    "    1. fare resample a quartorario per poter integrare con load (usa resemple + interpolate con method linear) e salva il risultato in w_15\n",
    "    \n",
    "    2. merge con df load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample a 15 minuti con interpolazione lineare (hint: resample , interpolate )\n",
    "w_15 = ...\n",
    "#w_15.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fccc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge con il DataFrame load\n",
    "df_full = pd.merge(\n",
    "    ... , # dataframe di sinistra (df) con il load \n",
    "    ... , # dataframe di destra (w_15) con la temperatura\n",
    "    on=..., # Colonna comune su cui fare la join (Date)\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "# how left -> left join (tiene tutti i record di df, aggiunge temperatura se presente)\n",
    "# perché temperatura non ha i valori dell'ultima ora dell'anno (verifica con .tail() di df e w_15)\n",
    "# ... completa qui ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mancano i dati dell'ultima ora del 2025, usiamo ffill\n",
    "df_full['Temperature_C'] = df_full['Temperature_C'].ffill()\n",
    "# verifica che non ci siano più NaN con .tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizza la temperatura con px.line()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ecc120",
   "metadata": {},
   "source": [
    "# STEP 6: Forecast con temperatura (Prophet + regressore)\n",
    "\n",
    "In questo step facciamo una previsione usando Prophet con la temperatura come variabile esogena.\n",
    "La serie del carico è **quartoraria**, quindi anche il future dataset e la temperatura devono essere allineati a **15 minuti**.\n",
    "\n",
    "Obiettivo:\n",
    "- costruire `future` a 15 minuti;\n",
    "- recuperare la **temperatura di previsione** da Open-Meteo sullo stesso periodo;\n",
    "- allinearla ai timestamp del future dataset;\n",
    "- calcolare forecast e visualizzare forecast + componenti.\n",
    "\n",
    "Fonte API (forecast): https://open-meteo.com/en/docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# 1) Selezione e rinomina (Prophet vuole ds, y + regressori)\n",
    "df_prophet = ...\n",
    "#df_prophet = df_prophet.reset_index(drop=True)\n",
    "\n",
    "# 2) Inizializzazione modello + regressore (.add_regressor come visto nel notebook 07)\n",
    "#m = ...\n",
    "#m.\n",
    "\n",
    "# 3) Fit\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "# -----------------------\n",
    "# 1) Future dates (3 giorni quartorari)\n",
    "# -----------------------\n",
    "future = m.make_future_dataframe(periods=..., freq=\"15min\")\n",
    "\n",
    "# -----------------------\n",
    "# 2) Temperatura futura da Open-Meteo (Forecast API)\n",
    "# -----------------------\n",
    "lat, lon = 45.4642, 9.1900  # Milano\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    \"latitude\": lat,\n",
    "    \"longitude\": lon,\n",
    "    \"hourly\": \"temperature_2m\",\n",
    "    \"timezone\": \"Europe/Rome\",\n",
    "    \"start_date\": future['ds'].min().strftime('%Y-%m-%d'),\n",
    "    \"end_date\": future['ds'].max().strftime('%Y-%m-%d'),\n",
    "    \"timezone\": \"Europe/Rome\" # \"UTC\"\n",
    "\n",
    "}\n",
    "\n",
    "r = requests.get(url, params=params, timeout=30)\n",
    "r.raise_for_status()\n",
    "data = r.json()[\"hourly\"]\n",
    "\n",
    "df_temp_future = pd.DataFrame({\n",
    "    \"ds\": pd.to_datetime(data[\"time\"]),\n",
    "    \"temperature\": data[\"temperature_2m\"],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61000f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3) Merge: future + temperatura\n",
    "# -----------------------\n",
    "future = future.merge(df_temp_future, on=\"ds\", how=\"left\").sort_values(\"ds\")\n",
    "# In caso di piccoli buchi (può capitare per edge-case), riempiamo in modo semplice\n",
    "future[\"temperature\"] = future[\"temperature\"].ffill().bfill()\n",
    "\n",
    "# -----------------------\n",
    "# 4) Previsione + plot\n",
    "# -----------------------\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
